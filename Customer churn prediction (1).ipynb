{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae352778",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"C:/test.csv\"  \n",
    "data = pd.read_csv(url)\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c633609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "# Pairplot for general overview\n",
    "sns.pairplot(data, hue='total_day_minutes')  \n",
    "# Correlation heatmap\n",
    "correlation_matrix = data.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Churn\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data['total_day_minutes'])  # Assuming 'international_plan' is the churn indicator\n",
    "plt.title(\"Churn Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['total_day_calls', 'total_day_charge', 'total_eve_minutes']  \n",
    "for feature in numerical_features:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(data[feature], kde=True)\n",
    "    plt.title(f\"Distribution of {feature}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dcc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['state', 'international_plan', 'voice_mail_plan']  # Update with your features\n",
    "for feature in categorical_features:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.violinplot(x=feature, y='total_eve_calls', data=data)\n",
    "    plt.title(f\"{feature} vs total_eve_calls\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4977a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "import pandas as pd\n",
    "columns_to_delete = ['state','area_code']\n",
    "\n",
    "# Use the drop method to delete the specified columns\n",
    "data.drop(columns=columns_to_delete, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f3a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf215af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(columns=[\"total_intl_calls\"])\n",
    "y = data[\"total_intl_calls\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e107c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512746ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9232c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "model = LogisticRegression(max_iter=1000)# Import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Preprocess the categorical variables using one-hot encoding\n",
    "#data = pd.get_dummies(data, columns=[\"Geography\", \"Gender\"])\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = data.drop(\"number_customer_service_calls\", axis=1)\n",
    "y = data[\"number_customer_service_calls\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)  # Specify 'weighted' for multiclass\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')  # Specify 'weighted' for multiclass\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  # Specify 'weighted' for multiclass\n",
    "    \n",
    "    results[name] = {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1\": f1}\n",
    "\n",
    "# Display evaluation results\n",
    "print(\"Model Evaluation Results:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']:.2f}\")\n",
    "    print(f\"Precision: {metrics['Precision']:.2f}\")\n",
    "    print(f\"Recall: {metrics['Recall']:.2f}\")\n",
    "    print(f\"F1 Score: {metrics['F1']:.2f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f66ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(results, key=lambda k: results[k][\"F1\"])\n",
    "print(\"Best Performing Model:\", best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c214e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deployment\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data\n",
    "input_data = (15, 28, 57, 123, 6, 58, 26, 17, 19, 38, 17, 17, 12, 12, 15)\n",
    "\n",
    "# Changing the input_data to a numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# Reshape the array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n",
    "\n",
    "# Assuming you have a DataFrame named 'data' and want to predict 'number_customer_service_calls'\n",
    "# Replace 'X' and 'y' with your actual features and target variable\n",
    "X = data.drop(\"number_customer_service_calls\", axis=1)\n",
    "y = data[\"number_customer_service_calls\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train a Logistic Regression model# Create and train a Logistic Regression model with increased max_iter\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Now, you can make predictions with the trained model\n",
    "prediction = logistic_regression.predict(input_data_reshaped)\n",
    "\n",
    "if prediction[0] == 0:\n",
    "    print(\"Churn: No\")\n",
    "else:\n",
    "    print(\"Churn: Yes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb6e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
